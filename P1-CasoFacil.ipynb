{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1dj7ny4ef03S9L6-wyJdJmhK1nCQX6_ZX",
      "authorship_tag": "ABX9TyMZ4FhaxeQtRq0pnJD+wD0O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcarvajal208/Proyecto1Arqui-IELE3222-/blob/master/P1-CasoFacil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9fYVKd4NVmu",
        "colab_type": "text"
      },
      "source": [
        "#Se importan las librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTmpoaPVNs9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "322c8666-1b15-4d53-f102-5a5585fe531f"
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14.0 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.34.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (3.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.18.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.27.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14.0) (1.14.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14.0) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0) (3.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlUVSk_p-jK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "import os \n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn import preprocessing, model_selection\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import tensorflow.python.keras as keras\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOEm0GIAJt64",
        "colab_type": "text"
      },
      "source": [
        "#Se cargan los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teybXDkyjTby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mundo1 = zipfile.ZipFile(\"Mun1.zip\", mode=\"r\")\n",
        "mundo1.extractall(None)\n",
        "mundo8 = zipfile.ZipFile(\"Mun8.zip\", mode=\"r\") \n",
        "mundo8.extractall(None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoOfqHBdLRxV",
        "colab_type": "text"
      },
      "source": [
        "#Se definen las variables 'X' y 'y'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OclGdAAnmVFB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagenes = []\n",
        "nivel = []\n",
        "imagenes1 = mundo1.namelist()\n",
        "imagenes8 = mundo8.namelist()\n",
        "#Se agregan las imagenes del mundo 1\n",
        "i = 1\n",
        "while(i<len(imagenes1)):\n",
        "  filepath = os.path.join(\"\", imagenes1[i]) \n",
        "  image = plt.imread(filepath)\n",
        "  imagenes.append(image)\n",
        "  nivel.append(0)\n",
        "  i += 1\n",
        "#Se agreagan las imagenes del mundo 8\n",
        "i = 1\n",
        "while(i<len(imagenes8)):\n",
        "  filepath = os.path.join(\"\", imagenes8[i]) \n",
        "  image = plt.imread(filepath)\n",
        "  imagenes.append(image)\n",
        "  nivel.append(1)\n",
        "  i += 1\n",
        "#Se define la salida por categorias, para que se puedan distinguir las clases.\n",
        "y = to_categorical(np.array(nivel))\n",
        "X = np.array(imagenes, dtype=np.uint8)  \n",
        "print('Dimensiones de las variables: ', X.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eno0dMvLJz7p",
        "colab_type": "text"
      },
      "source": [
        "#Preprocesamiento de datos\n",
        "\n",
        "\n",
        "1.   Se realiza el conjunto de entrenamiento al tomar el 10% de los datos totales.\n",
        "2.   Se realiza el conjunto de validación al tomar el 10% de los datos de entrenamiento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "593x9HKD2feD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se definen los porcentajes de entrenamiento y validación\n",
        "porcentajeEntrenamiento = 0.8\n",
        "porcentajeValidación = 0.9\n",
        "#Se determinan los datos de entrenamiento, prueba y validación\n",
        "x_entrenamiento, x_prueba, y_entrenamiento, y_prueba = model_selection.train_test_split(X,y,test_size=1-porcentajeEntrenamiento)\n",
        "x_entrenamiento, x_validacion, y_entrenamiento, y_validacion = model_selection.train_test_split(x_entrenamiento,y_entrenamiento,test_size=1-porcentajeValidación)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdEmJ-u-40ws",
        "colab_type": "text"
      },
      "source": [
        "#Se crea la red neuronal\n",
        "\n",
        "\n",
        "1.   La red neuronal se realizará a partir de keras\n",
        "2.   La red va a ser de tipo sequencial, para poder trabajar con diferentes capas, que se encarguen de diferentes funciones.\n",
        "3.   La primera capa es de tipo Conv2D, esto con el fin de especificar que se esta recibiendo una imagen de dimenciones (200,240,3). Tambien se especifica que su activación es de tipo relu, ya que siempre se recomienda hacer pooling justo despues de haber aplicado una capa con no-linealidad.\n",
        "4.   Lo siguiente es utilizar MaxPooling2D, para agrupar la presencia de aquellos patrones que se repiten con mayor frecuencia en cada segmento de la imagen.\n",
        "5.   A continuación se utiliza Dropout, para igualar a 0 un pequeño porcentaje de la información y con esto evitar overfitting en el entrenamiento.\n",
        "6.   Se utiliza flatten para acoplar los datos que salen de la capa dentreada y ajustarlos para que sirvan como entrada de la capa escondida de clasificación que se utiliza.\n",
        "7.   Se establece una capa central para para clasificación y se utiliza una activacion tipo relu, ya que sabemos suele entregar los mejores resultados en clasificación.\n",
        "8.   Nuevamente utilizamos Dropout para evitar overfitting.\n",
        "9.   Ya para terminar se crea una capa se salida con activación softmax para comprimir los nCentral datos obtenidos por la capa de clasificación, en tan solo nFinal datos que corresponderan al npumero de salidas.\n",
        "10.  Por ultimo se realiza la compilación de la red, la cual cuenta con:\n",
        "      1.  Entropia cruzada como función de error, dado que estamos haciendo un clasificador.\n",
        "      2.  Descenso de gradiente estocastico como algoritmo de optimización.\n",
        "      3.  La tasa de aprendisaje se fijo en 0.0005, luego de varias pruebas.\n",
        "      4.  Ademas tambien se indica que debe retornar el porcentaje de aciertos del entrenamiento.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nlzoNNo5Axo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Función que crea la red neuronal con base en el número de neuronas de cada una de sus capas\n",
        "def crearRed(nInicial, nCentral, nSalida):\n",
        "  #Se crea la red sequencial\n",
        "  RedNeuronal = Sequential()\n",
        "  #Se crea la capa de entrada\n",
        "  RedNeuronal.add(Conv2D(nInicial, kernel_size=(3, 3),activation='relu',padding='same',input_shape=(200, 240, 3)))\n",
        "  #Se realiza una agrupación de datos\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  RedNeuronal.add(MaxPooling2D())\n",
        "  #Se ajusta los datos para conectarlos a la siguiente capa\n",
        "  RedNeuronal.add(Dropout(0.5))\n",
        "  RedNeuronal.add(Flatten())\n",
        "  #Se crea la capa central de clasificación\n",
        "  RedNeuronal.add(Dense(nCentral, activation='relu')) \n",
        "  RedNeuronal.add(Dropout(0.5)) \n",
        "  #Se crea la capa de salida\n",
        "  RedNeuronal.add(Dense(nSalida, activation='softmax'))\n",
        "  #Se compila la red\n",
        "  tasa = 0.0005\n",
        "  RedNeuronal.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=tasa,decay=tasa/100), metrics=['accuracy'])\n",
        "  #Se retorna la red creada\n",
        "  return RedNeuronal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxOVgkA-Ic1T",
        "colab_type": "text"
      },
      "source": [
        "#Validación de número de neuronas\n",
        "\n",
        "\n",
        "1.   Se van a realizar pruebas de 10 en 10 en cada una de las capas.\n",
        "2.   Dado que nuestra variable de salida esta restringida a dos posibles salidas debido a la funcion to_categorical(), la ultima capa tambien debera ser de dos salidas, para que la respuesta se pueda comparar con los datos reales.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2GZHlv9LHVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se crea el vector con el número de neuronas\n",
        "neuronas = [30, 40, 50, 60]\n",
        "i = 0\n",
        "#Se recorre la capa de entrada\n",
        "while(i<len(neuronas)):\n",
        "  j=0\n",
        "  #Se recorre la capa central\n",
        "  while(j<len(neuronas)):\n",
        "    #Se crea y valida la red neuronal\n",
        "    RedNeuronal = crearRed(neuronas[i], neuronas[j], 2)\n",
        "    fit = RedNeuronal.fit(x_validacion, y_validacion, batch_size=64, epochs=10, verbose=0)\n",
        "    print('[',neuronas[i],',',neuronas[j],', 2 ]:','Tasa de acierto: ',(fit.history['accuracy']))\n",
        "    j += 1\n",
        "  i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNqqU-HhaqYJ",
        "colab_type": "text"
      },
      "source": [
        "#Se selecciona la red neuronal a crear\n",
        "\n",
        "1.   Se va a tomar la red con las neuronas [50, 50, 2], dado que se obxervaron muy buenos resultados para este tipo de red.\n",
        "2.   Se entrena la red con los datos de en trenamiento y esto luego de 5 epochs.\n",
        "3.   Se guarda la red obtenida.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elwgtekpbUHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se crea la red neuronal\n",
        "RedNeuronal = crearRed(50, 50, 2)\n",
        "#Se muestra como esta compuesta la red\n",
        "RedNeuronal.summary()\n",
        "#Se entrena la red\n",
        "fit = RedNeuronal.fit(x_entrenamiento, y_entrenamiento, batch_size=64, epochs=25, verbose=1)\n",
        "#Se guarda la red creada\n",
        "RedNeuronal.save(\"CasoSencillo.h5py\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zd2LGHuZC-e",
        "colab_type": "text"
      },
      "source": [
        "#Evaluación de la red neuronal\n",
        "Una vez evaluado el error empirico y rteniendo en cuenta el número de datos \\\\\n",
        "Se observa que el indice de confianza es :\n",
        "##$(1-\\delta) = (1 - 2/\\exp(|S{\\small text}|{ \\cdot 2\\varepsilon^2 }))$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NAUJW3NZUs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Se prueba la red neuronal\n",
        "prueba = RedNeuronal.evaluate(x_prueba, y_prueba, verbose=0)\n",
        "#Se calcula el erro empirico, numero de datos y indice de confianza\n",
        "E_empirico = 1 - prueba[1]\n",
        "N_datos = y_prueba.shape[0]\n",
        "confianza = 1 - 2/math.exp(N_datos*2*(E_empirico**2))\n",
        "print('Número de datos de prueba = ' + str(N_datos))\n",
        "print('Error empirico = ' + str(E_empirico))\n",
        "print('indice de confianza = ' + str(confianza))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev5NDvwSlh-_",
        "colab_type": "text"
      },
      "source": [
        "#Referencias\n",
        "\n",
        "\n",
        "*   [1]   \"Home - Keras Documentation\", Keras.io, 2020. [Online]. Available: https://keras.io/. [Accessed: 20- Mar- 2020].\n",
        "*   [2]   \"Clasificación de Imágenes en Python\", Aprende Machine Learning, 2020. [Online]. Available: https://www.aprendemachinelearning.com/clasificacion-de-imagenes-en-python/. [Accessed: 20- Mar- 2020].\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}